{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-05T06:09:20.567199Z","iopub.execute_input":"2023-05-05T06:09:20.567947Z","iopub.status.idle":"2023-05-05T06:09:20.573138Z","shell.execute_reply.started":"2023-05-05T06:09:20.567903Z","shell.execute_reply":"2023-05-05T06:09:20.572007Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.575363Z","iopub.execute_input":"2023-05-05T06:09:20.576005Z","iopub.status.idle":"2023-05-05T06:09:20.587533Z","shell.execute_reply.started":"2023-05-05T06:09:20.575973Z","shell.execute_reply":"2023-05-05T06:09:20.586654Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D,Flatten,Dense,MaxPooling2D,Dropout,BatchNormalization\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.589024Z","iopub.execute_input":"2023-05-05T06:09:20.589717Z","iopub.status.idle":"2023-05-05T06:09:20.599980Z","shell.execute_reply.started":"2023-05-05T06:09:20.589685Z","shell.execute_reply":"2023-05-05T06:09:20.599162Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ecg_path = '/kaggle/input/dataset'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.612514Z","iopub.execute_input":"2023-05-05T06:09:20.613119Z","iopub.status.idle":"2023-05-05T06:09:20.620171Z","shell.execute_reply.started":"2023-05-05T06:09:20.613088Z","shell.execute_reply":"2023-05-05T06:09:20.619252Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"labels = os.listdir(ecg_path)\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.621678Z","iopub.execute_input":"2023-05-05T06:09:20.622336Z","iopub.status.idle":"2023-05-05T06:09:20.633455Z","shell.execute_reply.started":"2023-05-05T06:09:20.622305Z","shell.execute_reply":"2023-05-05T06:09:20.632433Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['Normal Person ECG Images (859)',\n 'ECG Images of Myocardial Infarction Patients (77)',\n 'ECG Images of Patient that have abnormal heart beats (548)',\n 'ECG Images of COVID-19 Patients (250)',\n 'ECG Images of Patient that have History of MI (203)']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for label in labels:\n#     targetPath = os.path.join(ecg_path,label)\n# #     print(len(os.listdir(targetPath)))\n# #     img_num = len(os.listdir(targetPath))\n#     print()\n#     print()\n#     print()\n    \n#     last_path = shuffle(os.listdir(targetPath), random_state=101)\n#     for i in last_path:\n#         img_path = os.path.join(targetPath,i)\n#         print(img_path)\n#         train.append(img_path)\n       \n\n        \n# #         img = cv2.resize(img,(image_size,image_size))\n# #         X_train.append(img)\n# #         Y_train.append(i)  ","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.635032Z","iopub.execute_input":"2023-05-05T06:09:20.635674Z","iopub.status.idle":"2023-05-05T06:09:20.640034Z","shell.execute_reply.started":"2023-05-05T06:09:20.635643Z","shell.execute_reply":"2023-05-05T06:09:20.639135Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# for i in labels:\n#     targetPath = os.path.join(ecg_path,i)\n#     # print(targetPath)\n#     for j in os.listdir(targetPath):\n#         img = cv2.imread(os.path.join(targetPath,j))\n\n        \n#         X_train.append(img)\n#         Y_train.append(i)    ","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.641521Z","iopub.execute_input":"2023-05-05T06:09:20.642149Z","iopub.status.idle":"2023-05-05T06:09:20.653075Z","shell.execute_reply.started":"2023-05-05T06:09:20.642116Z","shell.execute_reply":"2023-05-05T06:09:20.652261Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.654317Z","iopub.execute_input":"2023-05-05T06:09:20.654930Z","iopub.status.idle":"2023-05-05T06:09:20.664549Z","shell.execute_reply.started":"2023-05-05T06:09:20.654898Z","shell.execute_reply":"2023-05-05T06:09:20.663619Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['Normal Person ECG Images (859)',\n 'ECG Images of Myocardial Infarction Patients (77)',\n 'ECG Images of Patient that have abnormal heart beats (548)',\n 'ECG Images of COVID-19 Patients (250)',\n 'ECG Images of Patient that have History of MI (203)']"},"metadata":{}}]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1./255,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n    validation_split=0.2) # Set the validation split\n\n# Generate batches of augmented ECG images for training\ntrain_set = datagen.flow_from_directory(\n    ecg_path,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    classes=labels,\n    subset='training') # Set the subset to training data\n\n# Generate batches of augmented ECG images for validation\ntest_set = datagen.flow_from_directory(\n    ecg_path,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    classes=labels,\n    subset='validation') # Set the subset to validation data","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:20.667169Z","iopub.execute_input":"2023-05-05T06:09:20.667760Z","iopub.status.idle":"2023-05-05T06:09:24.975570Z","shell.execute_reply.started":"2023-05-05T06:09:20.667728Z","shell.execute_reply":"2023-05-05T06:09:24.974736Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Found 1548 images belonging to 5 classes.\nFound 384 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu',input_shape=(224,224,3)))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(5,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:24.979004Z","iopub.execute_input":"2023-05-05T06:09:24.979268Z","iopub.status.idle":"2023-05-05T06:09:27.724458Z","shell.execute_reply.started":"2023-05-05T06:09:24.979244Z","shell.execute_reply":"2023-05-05T06:09:27.723569Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:27.725643Z","iopub.execute_input":"2023-05-05T06:09:27.725956Z","iopub.status.idle":"2023-05-05T06:09:27.743893Z","shell.execute_reply.started":"2023-05-05T06:09:27.725924Z","shell.execute_reply":"2023-05-05T06:09:27.743115Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.fit(x = train_set, validation_data = test_set, epochs = 25)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T06:09:27.746903Z","iopub.execute_input":"2023-05-05T06:09:27.747176Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"2023-05-05 06:09:30.566463: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"49/49 [==============================] - 68s 1s/step - loss: 1.4092 - accuracy: 0.3960 - val_loss: 1.3535 - val_accuracy: 0.4453\nEpoch 2/25\n49/49 [==============================] - 37s 756ms/step - loss: 1.3590 - accuracy: 0.4444 - val_loss: 1.3414 - val_accuracy: 0.4453\nEpoch 3/25\n49/49 [==============================] - 35s 719ms/step - loss: 1.3553 - accuracy: 0.4432 - val_loss: 1.3396 - val_accuracy: 0.4453\nEpoch 4/25\n49/49 [==============================] - 35s 719ms/step - loss: 1.3540 - accuracy: 0.4444 - val_loss: 1.3407 - val_accuracy: 0.4453\nEpoch 5/25\n49/49 [==============================] - 40s 813ms/step - loss: 1.3553 - accuracy: 0.4444 - val_loss: 1.3401 - val_accuracy: 0.4453\nEpoch 6/25\n49/49 [==============================] - 35s 724ms/step - loss: 1.3605 - accuracy: 0.4444 - val_loss: 1.3496 - val_accuracy: 0.4453\nEpoch 7/25\n49/49 [==============================] - 36s 742ms/step - loss: 1.3495 - accuracy: 0.4444 - val_loss: 1.3451 - val_accuracy: 0.4453\nEpoch 8/25\n49/49 [==============================] - 35s 722ms/step - loss: 1.3566 - accuracy: 0.4444 - val_loss: 1.3451 - val_accuracy: 0.4453\nEpoch 9/25\n49/49 [==============================] - 39s 795ms/step - loss: 1.3557 - accuracy: 0.4444 - val_loss: 1.3437 - val_accuracy: 0.4453\nEpoch 10/25\n49/49 [==============================] - 36s 731ms/step - loss: 1.3554 - accuracy: 0.4444 - val_loss: 1.3420 - val_accuracy: 0.4453\nEpoch 11/25\n49/49 [==============================] - 36s 738ms/step - loss: 1.3500 - accuracy: 0.4438 - val_loss: 1.3422 - val_accuracy: 0.4453\nEpoch 12/25\n49/49 [==============================] - 35s 719ms/step - loss: 1.3559 - accuracy: 0.4444 - val_loss: 1.3407 - val_accuracy: 0.4453\nEpoch 13/25\n49/49 [==============================] - 36s 732ms/step - loss: 1.3513 - accuracy: 0.4444 - val_loss: 1.3406 - val_accuracy: 0.4453\nEpoch 14/25\n49/49 [==============================] - 37s 746ms/step - loss: 1.3471 - accuracy: 0.4444 - val_loss: 1.3436 - val_accuracy: 0.4453\nEpoch 15/25\n49/49 [==============================] - ETA: 0s - loss: 1.3549 - accuracy: 0.4444","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}